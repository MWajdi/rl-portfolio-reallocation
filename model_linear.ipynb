{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples loaded: 55000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datetime import datetime\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def load_data_from_json(json_file):\n",
    "    \"\"\"\n",
    "    Loads the JSON file created by `create_train_json` and returns\n",
    "    a sorted list of (timestamp_dt, X_window, y_val).\n",
    "    \"\"\"\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    records = []\n",
    "    for ts_str, (x_window, y_val) in data.items():\n",
    "        dt = datetime.fromisoformat(ts_str)  # Convert string to datetime\n",
    "        records.append((dt, x_window, y_val))\n",
    "    \n",
    "    # Sort by datetime\n",
    "    records.sort(key=lambda r: r[0])\n",
    "    return records\n",
    "\n",
    "def prepare_splits(records, train_size=30000, val_size=10000, test_size=15000):\n",
    "    \"\"\"\n",
    "    Splits the sorted records into train, val, and test sets (chronologically).\n",
    "    \n",
    "    Returns (X_train, y_train, X_val, y_val, X_test, y_test) as NumPy arrays.\n",
    "    \"\"\"\n",
    "    total_needed = train_size + val_size + test_size\n",
    "    subset = records[:total_needed]  # in case you have more data\n",
    "    \n",
    "    X_all = []\n",
    "    y_all = []\n",
    "    \n",
    "    for _, x_win, y_val in subset:\n",
    "        X_all.append(x_win)\n",
    "        y_all.append(y_val)\n",
    "    \n",
    "    X_all = np.array(X_all, dtype=np.float32)\n",
    "    y_all = np.array(y_all, dtype=np.float32)\n",
    "    \n",
    "    X_train = X_all[:train_size]\n",
    "    y_train = y_all[:train_size]\n",
    "    \n",
    "    X_val = X_all[train_size : train_size+val_size]\n",
    "    y_val = y_all[train_size : train_size+val_size]\n",
    "    \n",
    "    X_test = X_all[train_size+val_size : train_size+val_size+test_size]\n",
    "    y_test = y_all[train_size+val_size : train_size+val_size+test_size]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# Load data from JSON\n",
    "all_records = load_data_from_json(\"BTC_train_data.json\")\n",
    "print(\"Total samples loaded:\", len(all_records))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (30000, 100) (30000,)\n",
      "Val shape:   (10000, 100) (10000,)\n",
      "Test shape:  (15000, 100) (15000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split into train/val/test\n",
    "X_train_np, y_train_np, X_val_np, y_val_np, X_test_np, y_test_np = prepare_splits(\n",
    "    all_records,\n",
    "    train_size=30000,\n",
    "    val_size=10000,\n",
    "    test_size=15000\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train_np.shape, y_train_np.shape)\n",
    "print(\"Val shape:  \", X_val_np.shape,   y_val_np.shape)\n",
    "print(\"Test shape: \", X_test_np.shape,  y_test_np.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X)\n",
    "        self.y = torch.from_numpy(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Return (features, target)\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "# Create dataset objects\n",
    "train_dataset = TimeSeriesDataset(X_train_np, y_train_np)\n",
    "val_dataset   = TimeSeriesDataset(X_val_np,   y_val_np)\n",
    "test_dataset  = TimeSeriesDataset(X_test_np,  y_test_np)\n",
    "\n",
    "# Create DataLoader objects\n",
    "#   - shuffle only for train\n",
    "batch_size = 256\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_dim = X_train_np.shape[1]\n",
    "\n",
    "model = nn.Linear(in_features=input_dim, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/20] Train MSE: 3258.8954 | Val MSE: 2316.8016\n",
      "[Epoch 2/20] Train MSE: 2377.2327 | Val MSE: 2328.3594\n",
      "[Epoch 3/20] Train MSE: 2386.0943 | Val MSE: 2331.5752\n",
      "[Epoch 4/20] Train MSE: 2337.9505 | Val MSE: 2264.4180\n",
      "[Epoch 5/20] Train MSE: 2370.8813 | Val MSE: 2259.6350\n",
      "[Epoch 6/20] Train MSE: 2397.1665 | Val MSE: 2323.6986\n",
      "[Epoch 7/20] Train MSE: 2407.1159 | Val MSE: 2230.5633\n",
      "[Epoch 8/20] Train MSE: 2368.6187 | Val MSE: 2732.6583\n",
      "[Epoch 9/20] Train MSE: 2411.9937 | Val MSE: 2243.0132\n",
      "[Epoch 10/20] Train MSE: 2328.0142 | Val MSE: 2212.5552\n",
      "[Epoch 11/20] Train MSE: 2288.1631 | Val MSE: 2223.5644\n",
      "[Epoch 12/20] Train MSE: 2285.3339 | Val MSE: 2194.7944\n",
      "[Epoch 13/20] Train MSE: 2292.6956 | Val MSE: 2296.9722\n",
      "[Epoch 14/20] Train MSE: 2295.4115 | Val MSE: 2358.8071\n",
      "[Epoch 15/20] Train MSE: 2298.1767 | Val MSE: 2161.0060\n",
      "[Epoch 16/20] Train MSE: 2364.6597 | Val MSE: 2457.3042\n",
      "[Epoch 17/20] Train MSE: 2280.9746 | Val MSE: 2150.3453\n",
      "[Epoch 18/20] Train MSE: 2213.7897 | Val MSE: 2112.2178\n",
      "[Epoch 19/20] Train MSE: 2237.5467 | Val MSE: 2097.0313\n",
      "[Epoch 20/20] Train MSE: 2273.0961 | Val MSE: 2090.1144\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=10, lr=1e-3):\n",
    "    # Choose an optimizer (Adam or SGD)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # ---- TRAINING PHASE ----\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        \n",
    "        for batch_x, batch_y in train_loader:\n",
    "            # batch_x: shape (batch_size, window_size)\n",
    "            # batch_y: shape (batch_size)\n",
    "            \n",
    "            # Forward pass\n",
    "            pred = model(batch_x)  # shape (batch_size, 1)\n",
    "            pred = pred.squeeze(1) # shape (batch_size)\n",
    "            \n",
    "            loss = F.mse_loss(pred, batch_y)\n",
    "            \n",
    "            # Backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        # Average training loss\n",
    "        train_loss_mean = np.mean(train_losses)\n",
    "        \n",
    "        # ---- VALIDATION PHASE ----\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in val_loader:\n",
    "                pred = model(batch_x).squeeze(1)\n",
    "                loss = F.mse_loss(pred, batch_y)\n",
    "                val_losses.append(loss.item())\n",
    "        \n",
    "        val_loss_mean = np.mean(val_losses)\n",
    "        \n",
    "        print(f\"[Epoch {epoch}/{epochs}] \"\n",
    "              f\"Train MSE: {train_loss_mean:.4f} | \"\n",
    "              f\"Val MSE: {val_loss_mean:.4f}\")\n",
    "\n",
    "\n",
    "# Train for 20 epochs as an example\n",
    "train_model(model, train_loader, val_loader, epochs=20, lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
